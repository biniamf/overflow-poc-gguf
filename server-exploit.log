[GIN] 2026/01/15 - 22:51:44 | 200 |      16.768µs |       127.0.0.1 | HEAD     "/"
[GIN] 2026/01/15 - 22:51:44 | 200 |    4.567832ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2026/01/15 - 22:51:44 | 200 |    1.301939ms |       127.0.0.1 | POST     "/api/show"
llama_model_loader: loaded meta data with 22 key-value pairs and 12 tensors from /Users/[USER]/.ollama/models/blobs/sha256-a0c336e4562afb99fcbb191153584ddd571f4c8f83f18ee9b35d23d8b757c5e5 (version GGUF V3 (latest))
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: - kv   0:                       general.architecture str              = llama
llama_model_loader: - kv   1:                               general.name str              = benign-control
llama_model_loader: - kv   2:                          general.file_type u32              = 0
llama_model_loader: - kv   3:                           llama.vocab_size u32              = 100
llama_model_loader: - kv   4:                       llama.context_length u32              = 512
llama_model_loader: - kv   5:                     llama.embedding_length u32              = 64
llama_model_loader: - kv   6:                          llama.block_count u32              = 1
llama_model_loader: - kv   7:                  llama.feed_forward_length u32              = 128
llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 4
llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 4
llama_model_loader: - kv  10:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010
llama_model_loader: - kv  11:                       llama.rope.freq_base f32              = 10000.000000
llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama
llama_model_loader: - kv  13:                         tokenizer.ggml.pre str              = default
llama_model_loader: - kv  14:                      tokenizer.ggml.tokens arr[str,100]     = ["<unk>", "<s>", "</s>", "t0", "t1", ...
llama_model_loader: - kv  15:                      tokenizer.ggml.scores arr[f32,100]     = [0.000000, 0.000000, 0.000000, 0.0000...
llama_model_loader: - kv  16:                  tokenizer.ggml.token_type arr[i32,100]     = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
llama_model_loader: - kv  17:                tokenizer.ggml.bos_token_id u32              = 1
llama_model_loader: - kv  18:                tokenizer.ggml.eos_token_id u32              = 2
llama_model_loader: - kv  19:            tokenizer.ggml.unknown_token_id u32              = 0
llama_model_loader: - kv  20:               tokenizer.ggml.add_bos_token bool             = true
llama_model_loader: - kv  21:               tokenizer.ggml.add_eos_token bool             = false
llama_model_loader: - type  f32:   12 tensors
print_info: file format = GGUF V3 (latest)
print_info: file type   = all F32
print_info: file size   = 0.21 MiB (32.00 BPW) 
load: SPM vocabulary, but newline token not found: unordered_map::at: key not found! Using special_pad_id instead.load: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect
load: printing all EOG tokens:
load:   - 2 ('</s>')
load: special tokens cache size = 0
load: token to piece cache size = 0.0003 MB
print_info: arch             = llama
print_info: vocab_only       = 1
print_info: model type       = ?B
print_info: model params     = 53.95 K
print_info: general.name     = benign-control
print_info: vocab type       = SPM
print_info: n_vocab          = 100
print_info: n_merges         = 0
print_info: BOS token        = 1 '<s>'
print_info: EOS token        = 2 '</s>'
print_info: UNK token        = 0 '<unk>'
print_info: EOG token        = 2 '</s>'
print_info: max token length = 5
llama_model_load: vocab only - skipping tensors
time=2026-01-15T22:51:44.082+04:00 level=WARN source=server.go:167 msg="requested context size too large for model" num_ctx=4096 n_ctx_train=512
time=2026-01-15T22:51:44.082+04:00 level=INFO source=server.go:392 msg="starting runner" cmd="/Applications/Ollama.app/Contents/Resources/ollama runner --model /Users/[USER]/.ollama/models/blobs/sha256-a0c336e4562afb99fcbb191153584ddd571f4c8f83f18ee9b35d23d8b757c5e5 --port 51111"
time=2026-01-15T22:51:44.084+04:00 level=INFO source=sched.go:443 msg="system memory" total="32.0 GiB" free="10.3 GiB" free_swap="0 B"
time=2026-01-15T22:51:44.084+04:00 level=INFO source=server.go:459 msg="loading model" "model layers"=2 requested=-1
time=2026-01-15T22:51:44.084+04:00 level=INFO source=device.go:245 msg="model weights" device=CPU size="185.8 KiB"
time=2026-01-15T22:51:44.084+04:00 level=INFO source=device.go:256 msg="kv cache" device=CPU size="128.0 KiB"
time=2026-01-15T22:51:44.084+04:00 level=INFO source=device.go:272 msg="total memory" size="313.8 KiB"
time=2026-01-15T22:51:44.142+04:00 level=INFO source=runner.go:963 msg="starting go runner"
load_backend: loaded CPU backend from /Applications/Ollama.app/Contents/Resources/libggml-cpu-haswell.so
time=2026-01-15T22:51:44.218+04:00 level=INFO source=ggml.go:104 msg=system CPU.0.SSE3=1 CPU.0.SSSE3=1 CPU.0.AVX=1 CPU.0.AVX2=1 CPU.0.F16C=1 CPU.0.FMA=1 CPU.0.BMI2=1 CPU.0.LLAMAFILE=1 CPU.1.SSE3=1 CPU.1.SSSE3=1 CPU.1.LLAMAFILE=1 compiler=cgo(clang)
time=2026-01-15T22:51:44.218+04:00 level=INFO source=runner.go:999 msg="Server listening on 127.0.0.1:51111"
time=2026-01-15T22:51:44.231+04:00 level=INFO source=runner.go:893 msg=load request="{Operation:commit LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:false KvSize:512 KvCacheType: NumThreads:8 GPULayers:[] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
time=2026-01-15T22:51:44.231+04:00 level=INFO source=server.go:1294 msg="waiting for llama runner to start responding"
time=2026-01-15T22:51:44.232+04:00 level=INFO source=server.go:1328 msg="waiting for server to become available" status="llm server loading model"
llama_model_loader: loaded meta data with 22 key-value pairs and 12 tensors from /Users/[USER]/.ollama/models/blobs/sha256-a0c336e4562afb99fcbb191153584ddd571f4c8f83f18ee9b35d23d8b757c5e5 (version GGUF V3 (latest))
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: - kv   0:                       general.architecture str              = llama
llama_model_loader: - kv   1:                               general.name str              = benign-control
llama_model_loader: - kv   2:                          general.file_type u32              = 0
llama_model_loader: - kv   3:                           llama.vocab_size u32              = 100
llama_model_loader: - kv   4:                       llama.context_length u32              = 512
llama_model_loader: - kv   5:                     llama.embedding_length u32              = 64
llama_model_loader: - kv   6:                          llama.block_count u32              = 1
llama_model_loader: - kv   7:                  llama.feed_forward_length u32              = 128
llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 4
llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 4
llama_model_loader: - kv  10:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010
llama_model_loader: - kv  11:                       llama.rope.freq_base f32              = 10000.000000
llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama
llama_model_loader: - kv  13:                         tokenizer.ggml.pre str              = default
llama_model_loader: - kv  14:                      tokenizer.ggml.tokens arr[str,100]     = ["<unk>", "<s>", "</s>", "t0", "t1", ...
llama_model_loader: - kv  15:                      tokenizer.ggml.scores arr[f32,100]     = [0.000000, 0.000000, 0.000000, 0.0000...
llama_model_loader: - kv  16:                  tokenizer.ggml.token_type arr[i32,100]     = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
llama_model_loader: - kv  17:                tokenizer.ggml.bos_token_id u32              = 1
llama_model_loader: - kv  18:                tokenizer.ggml.eos_token_id u32              = 2
llama_model_loader: - kv  19:            tokenizer.ggml.unknown_token_id u32              = 0
llama_model_loader: - kv  20:               tokenizer.ggml.add_bos_token bool             = true
llama_model_loader: - kv  21:               tokenizer.ggml.add_eos_token bool             = false
llama_model_loader: - type  f32:   12 tensors
print_info: file format = GGUF V3 (latest)
print_info: file type   = all F32
print_info: file size   = 0.21 MiB (32.00 BPW) 
load: SPM vocabulary, but newline token not found: unordered_map::at: key not found! Using special_pad_id instead.load: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect
load: printing all EOG tokens:
load:   - 2 ('</s>')
load: special tokens cache size = 0
load: token to piece cache size = 0.0003 MB
print_info: arch             = llama
print_info: vocab_only       = 0
print_info: n_ctx_train      = 512
print_info: n_embd           = 64
print_info: n_layer          = 1
print_info: n_head           = 4
print_info: n_head_kv        = 4
print_info: n_rot            = 16
print_info: n_swa            = 0
print_info: is_swa_any       = 0
print_info: n_embd_head_k    = 16
print_info: n_embd_head_v    = 16
print_info: n_gqa            = 1
print_info: n_embd_k_gqa     = 64
print_info: n_embd_v_gqa     = 64
print_info: f_norm_eps       = 0.0e+00
print_info: f_norm_rms_eps   = 1.0e-05
print_info: f_clamp_kqv      = 0.0e+00
print_info: f_max_alibi_bias = 0.0e+00
print_info: f_logit_scale    = 0.0e+00
print_info: f_attn_scale     = 0.0e+00
print_info: n_ff             = 128
print_info: n_expert         = 0
print_info: n_expert_used    = 0
print_info: causal attn      = 1
print_info: pooling type     = 0
print_info: rope type        = 0
print_info: rope scaling     = linear
print_info: freq_base_train  = 10000.0
print_info: freq_scale_train = 1
print_info: n_ctx_orig_yarn  = 512
print_info: rope_finetuned   = unknown
print_info: model type       = ?B
print_info: model params     = 53.95 K
print_info: general.name     = benign-control
print_info: vocab type       = SPM
print_info: n_vocab          = 100
print_info: n_merges         = 0
print_info: BOS token        = 1 '<s>'
print_info: EOS token        = 2 '</s>'
print_info: UNK token        = 0 '<unk>'
print_info: EOG token        = 2 '</s>'
print_info: max token length = 5
load_tensors: loading model tensors, this can take a while... (mmap = false)
load_tensors:          CPU model buffer size =     0.21 MiB
llama_context: constructing llama_context
llama_context: n_seq_max     = 1
llama_context: n_ctx         = 512
llama_context: n_ctx_per_seq = 512
llama_context: n_batch       = 512
llama_context: n_ubatch      = 512
llama_context: causal_attn   = 1
llama_context: flash_attn    = disabled
llama_context: kv_unified    = false
llama_context: freq_base     = 10000.0
llama_context: freq_scale    = 1
llama_context:        CPU  output buffer size =     0.00 MiB
llama_kv_cache:        CPU KV buffer size =     0.12 MiB
llama_kv_cache: size =    0.12 MiB (   512 cells,   1 layers,  1/1 seqs), K (f16):    0.06 MiB, V (f16):    0.06 MiB
llama_context:        CPU compute buffer size =     5.76 MiB
llama_context: graph nodes  = 42
llama_context: graph splits = 1
time=2026-01-15T22:51:44.483+04:00 level=INFO source=server.go:1332 msg="llama runner started in 0.40 seconds"
time=2026-01-15T22:51:44.483+04:00 level=INFO source=sched.go:517 msg="loaded runners" count=1
time=2026-01-15T22:51:44.483+04:00 level=INFO source=server.go:1294 msg="waiting for llama runner to start responding"
time=2026-01-15T22:51:44.484+04:00 level=INFO source=server.go:1332 msg="llama runner started in 0.40 seconds"
[GIN] 2026/01/15 - 22:51:44 | 200 |  404.920527ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2026/01/15 - 22:51:47 | 200 |    5.102941ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2026/01/15 - 22:52:17 | 200 |    7.404567ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2026/01/15 - 22:52:47 | 200 |    8.852866ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2026/01/15 - 22:53:17 | 200 |     2.94743ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2026/01/15 - 22:53:35 | 200 |      17.594µs |       127.0.0.1 | HEAD     "/"
[GIN] 2026/01/15 - 22:53:35 | 200 |    1.968918ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2026/01/15 - 22:53:35 | 200 |    1.328657ms |       127.0.0.1 | POST     "/api/show"
llama_model_loader: loaded meta data with 22 key-value pairs and 12 tensors from /Users/[USER]/.ollama/models/blobs/sha256-804814d6c2a3ac31e543308830cce709fdc0dddb70bb464324b39cceed58c08a (version GGUF V3 (latest))
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: - kv   0:                       general.architecture str              = llama
llama_model_loader: - kv   1:                               general.name str              = exploit
llama_model_loader: - kv   2:                          general.file_type u32              = 0
llama_model_loader: - kv   3:                           llama.vocab_size u32              = 100
llama_model_loader: - kv   4:                       llama.context_length u32              = 512
llama_model_loader: - kv   5:                     llama.embedding_length u32              = 64
llama_model_loader: - kv   6:                          llama.block_count u32              = 1
llama_model_loader: - kv   7:                  llama.feed_forward_length u32              = 128
llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 4
llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 4
llama_model_loader: - kv  10:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010
llama_model_loader: - kv  11:                       llama.rope.freq_base f32              = 10000.000000
llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama
llama_model_loader: - kv  13:                         tokenizer.ggml.pre str              = default
llama_model_loader: - kv  14:                      tokenizer.ggml.tokens arr[str,100]     = ["<unk>", "<s>", "</s>", "t0", "t1", ...
llama_model_loader: - kv  15:                      tokenizer.ggml.scores arr[f32,100]     = [0.000000, 0.000000, 0.000000, 0.0000...
llama_model_loader: - kv  16:                  tokenizer.ggml.token_type arr[i32,100]     = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
llama_model_loader: - kv  17:                tokenizer.ggml.bos_token_id u32              = 1
llama_model_loader: - kv  18:                tokenizer.ggml.eos_token_id u32              = 2
llama_model_loader: - kv  19:            tokenizer.ggml.unknown_token_id u32              = 0
llama_model_loader: - kv  20:               tokenizer.ggml.add_bos_token bool             = true
llama_model_loader: - kv  21:               tokenizer.ggml.add_eos_token bool             = false
llama_model_loader: - type  f32:   12 tensors
print_info: file format = GGUF V3 (latest)
print_info: file type   = all F32
print_info: file size   = 0.18 MiB (0.00 BPW) 
load: SPM vocabulary, but newline token not found: unordered_map::at: key not found! Using special_pad_id instead.load: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect
load: printing all EOG tokens:
load:   - 2 ('</s>')
load: special tokens cache size = 0
load: token to piece cache size = 0.0003 MB
print_info: arch             = llama
print_info: vocab_only       = 1
print_info: model type       = ?B
print_info: model params     = 4611686.02 T
print_info: general.name     = exploit
print_info: vocab type       = SPM
print_info: n_vocab          = 100
print_info: n_merges         = 0
print_info: BOS token        = 1 '<s>'
print_info: EOS token        = 2 '</s>'
print_info: UNK token        = 0 '<unk>'
print_info: EOG token        = 2 '</s>'
print_info: max token length = 5
llama_model_load: vocab only - skipping tensors
time=2026-01-15T22:53:35.644+04:00 level=WARN source=server.go:167 msg="requested context size too large for model" num_ctx=4096 n_ctx_train=512
time=2026-01-15T22:53:35.644+04:00 level=INFO source=server.go:392 msg="starting runner" cmd="/Applications/Ollama.app/Contents/Resources/ollama runner --model /Users/[USER]/.ollama/models/blobs/sha256-804814d6c2a3ac31e543308830cce709fdc0dddb70bb464324b39cceed58c08a --port 51200"
time=2026-01-15T22:53:35.646+04:00 level=INFO source=sched.go:443 msg="system memory" total="32.0 GiB" free="10.2 GiB" free_swap="0 B"
time=2026-01-15T22:53:35.646+04:00 level=INFO source=server.go:459 msg="loading model" "model layers"=2 requested=-1
time=2026-01-15T22:53:35.646+04:00 level=INFO source=server.go:974 msg="model requires more memory than is currently available, evicting a model to make space" "loaded layers"=0
time=2026-01-15T22:53:35.648+04:00 level=INFO source=sched.go:443 msg="system memory" total="32.0 GiB" free="10.2 GiB" free_swap="0 B"
time=2026-01-15T22:53:35.648+04:00 level=INFO source=server.go:459 msg="loading model" "model layers"=2 requested=-1
time=2026-01-15T22:53:35.648+04:00 level=INFO source=device.go:245 msg="model weights" device=CPU size="185.8 KiB"
time=2026-01-15T22:53:35.648+04:00 level=INFO source=device.go:256 msg="kv cache" device=CPU size="128.0 KiB"
time=2026-01-15T22:53:35.648+04:00 level=INFO source=device.go:272 msg="total memory" size="313.8 KiB"
time=2026-01-15T22:53:35.708+04:00 level=INFO source=runner.go:963 msg="starting go runner"
load_backend: loaded CPU backend from /Applications/Ollama.app/Contents/Resources/libggml-cpu-haswell.so
time=2026-01-15T22:53:35.733+04:00 level=INFO source=ggml.go:104 msg=system CPU.0.SSE3=1 CPU.0.SSSE3=1 CPU.0.AVX=1 CPU.0.AVX2=1 CPU.0.F16C=1 CPU.0.FMA=1 CPU.0.BMI2=1 CPU.0.LLAMAFILE=1 CPU.1.SSE3=1 CPU.1.SSSE3=1 CPU.1.LLAMAFILE=1 compiler=cgo(clang)
time=2026-01-15T22:53:35.734+04:00 level=INFO source=runner.go:999 msg="Server listening on 127.0.0.1:51200"
time=2026-01-15T22:53:35.737+04:00 level=INFO source=runner.go:893 msg=load request="{Operation:commit LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:false KvSize:512 KvCacheType: NumThreads:8 GPULayers:[] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
time=2026-01-15T22:53:35.737+04:00 level=INFO source=server.go:1294 msg="waiting for llama runner to start responding"
time=2026-01-15T22:53:35.737+04:00 level=INFO source=server.go:1328 msg="waiting for server to become available" status="llm server loading model"
llama_model_loader: loaded meta data with 22 key-value pairs and 12 tensors from /Users/[USER]/.ollama/models/blobs/sha256-804814d6c2a3ac31e543308830cce709fdc0dddb70bb464324b39cceed58c08a (version GGUF V3 (latest))
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: - kv   0:                       general.architecture str              = llama
llama_model_loader: - kv   1:                               general.name str              = exploit
llama_model_loader: - kv   2:                          general.file_type u32              = 0
llama_model_loader: - kv   3:                           llama.vocab_size u32              = 100
llama_model_loader: - kv   4:                       llama.context_length u32              = 512
llama_model_loader: - kv   5:                     llama.embedding_length u32              = 64
llama_model_loader: - kv   6:                          llama.block_count u32              = 1
llama_model_loader: - kv   7:                  llama.feed_forward_length u32              = 128
llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 4
llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 4
llama_model_loader: - kv  10:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010
llama_model_loader: - kv  11:                       llama.rope.freq_base f32              = 10000.000000
llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama
llama_model_loader: - kv  13:                         tokenizer.ggml.pre str              = default
llama_model_loader: - kv  14:                      tokenizer.ggml.tokens arr[str,100]     = ["<unk>", "<s>", "</s>", "t0", "t1", ...
llama_model_loader: - kv  15:                      tokenizer.ggml.scores arr[f32,100]     = [0.000000, 0.000000, 0.000000, 0.0000...
llama_model_loader: - kv  16:                  tokenizer.ggml.token_type arr[i32,100]     = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
llama_model_loader: - kv  17:                tokenizer.ggml.bos_token_id u32              = 1
llama_model_loader: - kv  18:                tokenizer.ggml.eos_token_id u32              = 2
llama_model_loader: - kv  19:            tokenizer.ggml.unknown_token_id u32              = 0
llama_model_loader: - kv  20:               tokenizer.ggml.add_bos_token bool             = true
llama_model_loader: - kv  21:               tokenizer.ggml.add_eos_token bool             = false
llama_model_loader: - type  f32:   12 tensors
print_info: file format = GGUF V3 (latest)
print_info: file type   = all F32
print_info: file size   = 0.18 MiB (0.00 BPW) 
load: SPM vocabulary, but newline token not found: unordered_map::at: key not found! Using special_pad_id instead.load: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect
load: printing all EOG tokens:
load:   - 2 ('</s>')
load: special tokens cache size = 0
load: token to piece cache size = 0.0003 MB
print_info: arch             = llama
print_info: vocab_only       = 0
print_info: n_ctx_train      = 512
print_info: n_embd           = 64
print_info: n_layer          = 1
print_info: n_head           = 4
print_info: n_head_kv        = 4
print_info: n_rot            = 16
print_info: n_swa            = 0
print_info: is_swa_any       = 0
print_info: n_embd_head_k    = 16
print_info: n_embd_head_v    = 16
print_info: n_gqa            = 1
print_info: n_embd_k_gqa     = 64
print_info: n_embd_v_gqa     = 64
print_info: f_norm_eps       = 0.0e+00
print_info: f_norm_rms_eps   = 1.0e-05
print_info: f_clamp_kqv      = 0.0e+00
print_info: f_max_alibi_bias = 0.0e+00
print_info: f_logit_scale    = 0.0e+00
print_info: f_attn_scale     = 0.0e+00
print_info: n_ff             = 128
print_info: n_expert         = 0
print_info: n_expert_used    = 0
print_info: causal attn      = 1
print_info: pooling type     = 0
print_info: rope type        = 0
print_info: rope scaling     = linear
print_info: freq_base_train  = 10000.0
print_info: freq_scale_train = 1
print_info: n_ctx_orig_yarn  = 512
print_info: rope_finetuned   = unknown
print_info: model type       = ?B
print_info: model params     = 4611686.02 T
print_info: general.name     = exploit
print_info: vocab type       = SPM
print_info: n_vocab          = 100
print_info: n_merges         = 0
print_info: BOS token        = 1 '<s>'
print_info: EOS token        = 2 '</s>'
print_info: UNK token        = 0 '<unk>'
print_info: EOG token        = 2 '</s>'
print_info: max token length = 5
load_tensors: loading model tensors, this can take a while... (mmap = false)
ggml.c:3713: GGML_ASSERT(a->ne[2] == b->ne[1]) failed
(lldb) process attach --pid 34727
error: attach failed: attach failed (Not allowed to attach to process.  Look in the console messages (Console.app), near the debugserver entries, when the attach failed.  The subsystem that denied the attach permission will likely have logged an informative message about why it was denied.)
SIGABRT: abort
PC=0x7ff8029a9846 m=11 sigcode=0
signal arrived during cgo execution

goroutine 40 gp=0xc000504a80 m=11 mp=0xc000580808 [syscall]:
runtime.cgocall(0x10a207840, 0xc000090b58)
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/cgocall.go:167 +0x4b fp=0xc000090b30 sp=0xc000090af8 pc=0x1094ec02b
github.com/ollama/ollama/llama._Cfunc_llama_model_load_from_file(0x600000479d00, {0x0, 0x0, 0x0, 0x1, 0x0, 0x0, 0x10a206840, 0xc0001d2810, 0x0, ...})
	_cgo_gotypes.go:898 +0x47 fp=0xc000090b58 sp=0xc000090b30 pc=0x1098a5287
github.com/ollama/ollama/llama.LoadModelFromFile.func1(...)
	/Users/runner/work/ollama/ollama/llama/llama.go:303
github.com/ollama/ollama/llama.LoadModelFromFile({0x7ff7b6a85b0a, 0x72}, {{0x0, 0x0, 0x0}, 0x0, 0x0, 0x0, {0x0, 0x0, ...}, ...})
	/Users/runner/work/ollama/ollama/llama/llama.go:303 +0x56c fp=0xc000090da0 sp=0xc000090b58 pc=0x1098a850c
github.com/ollama/ollama/runner/llamarunner.(*Server).loadModel(0xc0000b4280, {{0x0, 0x0, 0x0}, 0x0, 0x0, 0x0, {0x0, 0x0, 0x0}, ...}, ...)
	/Users/runner/work/ollama/ollama/runner/llamarunner/runner.go:839 +0x9e fp=0xc000090ee8 sp=0xc000090da0 pc=0x10996073e
github.com/ollama/ollama/runner/llamarunner.(*Server).load.gowrap2()
	/Users/runner/work/ollama/ollama/runner/llamarunner/runner.go:932 +0x115 fp=0xc000090fe0 sp=0xc000090ee8 pc=0x109961a35
runtime.goexit({})
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/asm_amd64.s:1700 +0x1 fp=0xc000090fe8 sp=0xc000090fe0 pc=0x1094f76e1
created by github.com/ollama/ollama/runner/llamarunner.(*Server).load in goroutine 51
	/Users/runner/work/ollama/ollama/runner/llamarunner/runner.go:932 +0x88a

goroutine 1 gp=0xc000002380 m=nil [IO wait]:
runtime.gopark(0xc0004917e0?, 0x1095123f8?, 0x0?, 0x0?, 0x0?)
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/proc.go:435 +0xce fp=0xc000491790 sp=0xc000491770 pc=0x1094ef44e
runtime.netpollblock(0xc0004917e0?, 0x948a186?, 0x1?)
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/netpoll.go:575 +0xf7 fp=0xc0004917c8 sp=0xc000491790 pc=0x1094b5477
internal/poll.runtime_pollWait(0x152521730, 0x72)
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/netpoll.go:351 +0x85 fp=0xc0004917e8 sp=0xc0004917c8 pc=0x1094ee6a5
internal/poll.(*pollDesc).wait(0xc0001d0b00?, 0x9001723f0?, 0x0)
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/internal/poll/fd_poll_runtime.go:84 +0x27 fp=0xc000491810 sp=0xc0004917e8 pc=0x1095747c7
internal/poll.(*pollDesc).waitRead(...)
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/internal/poll/fd_poll_runtime.go:89
internal/poll.(*FD).Accept(0xc0001d0b00)
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/internal/poll/fd_unix.go:620 +0x295 fp=0xc0004918b8 sp=0xc000491810 pc=0x109579b95
net.(*netFD).accept(0xc0001d0b00)
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/net/fd_unix.go:172 +0x29 fp=0xc000491970 sp=0xc0004918b8 pc=0x1095ed989
net.(*TCPListener).accept(0xc000165900)
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/net/tcpsock_posix.go:159 +0x1b fp=0xc0004919c0 sp=0xc000491970 pc=0x10960261b
net.(*TCPListener).Accept(0xc000165900)
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/net/tcpsock.go:380 +0x30 fp=0xc0004919f0 sp=0xc0004919c0 pc=0x109601510
net/http.(*onceCloseListener).Accept(0xc000246090?)
	<autogenerated>:1 +0x24 fp=0xc000491a08 sp=0xc0004919f0 pc=0x10981ab24
net/http.(*Server).Serve(0xc000174100, {0x10ac70ca0, 0xc000165900})
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/net/http/server.go:3424 +0x30c fp=0xc000491b38 sp=0xc000491a08 pc=0x1097f23ec
github.com/ollama/ollama/runner/llamarunner.Execute({0xc0001101a0, 0x4, 0x4})
	/Users/runner/work/ollama/ollama/runner/llamarunner/runner.go:1000 +0x8f5 fp=0xc000491d08 sp=0xc000491b38 pc=0x1099623f5
github.com/ollama/ollama/runner.Execute({0xc000110190?, 0x0?, 0x0?})
	/Users/runner/work/ollama/ollama/runner/runner.go:22 +0xd4 fp=0xc000491d30 sp=0xc000491d08 pc=0x109a08834
github.com/ollama/ollama/cmd.NewCLI.func2(0xc0001f7200?, {0x10a7a04f1?, 0x4?, 0x10a7a04f5?})
	/Users/runner/work/ollama/ollama/cmd/cmd.go:1841 +0x45 fp=0xc000491d58 sp=0xc000491d30 pc=0x10a195f45
github.com/spf13/cobra.(*Command).execute(0xc0000eb508, {0xc00051f140, 0x4, 0x4})
	/Users/runner/go/pkg/mod/github.com/spf13/cobra@v1.7.0/command.go:940 +0x85c fp=0xc000491e78 sp=0xc000491d58 pc=0x1096660dc
github.com/spf13/cobra.(*Command).ExecuteC(0xc0000bc908)
	/Users/runner/go/pkg/mod/github.com/spf13/cobra@v1.7.0/command.go:1068 +0x3a5 fp=0xc000491f30 sp=0xc000491e78 pc=0x109666925
github.com/spf13/cobra.(*Command).Execute(...)
	/Users/runner/go/pkg/mod/github.com/spf13/cobra@v1.7.0/command.go:992
github.com/spf13/cobra.(*Command).ExecuteContext(...)
	/Users/runner/go/pkg/mod/github.com/spf13/cobra@v1.7.0/command.go:985
main.main()
	/Users/runner/work/ollama/ollama/main.go:12 +0x4d fp=0xc000491f50 sp=0xc000491f30 pc=0x10a196a2d
runtime.main()
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/proc.go:283 +0x28b fp=0xc000491fe0 sp=0xc000491f50 pc=0x1094bc1ab
runtime.goexit({})
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/asm_amd64.s:1700 +0x1 fp=0xc000491fe8 sp=0xc000491fe0 pc=0x1094f76e1

goroutine 2 gp=0xc000002e00 m=nil [force gc (idle)]:
runtime.gopark(0x0?, 0x0?, 0x0?, 0x0?, 0x0?)
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/proc.go:435 +0xce fp=0xc000084fa8 sp=0xc000084f88 pc=0x1094ef44e
runtime.goparkunlock(...)
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/proc.go:441
runtime.forcegchelper()
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/proc.go:348 +0xb3 fp=0xc000084fe0 sp=0xc000084fa8 pc=0x1094bc4f3
runtime.goexit({})
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/asm_amd64.s:1700 +0x1 fp=0xc000084fe8 sp=0xc000084fe0 pc=0x1094f76e1
created by runtime.init.7 in goroutine 1
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/proc.go:336 +0x1a

goroutine 3 gp=0xc0000036c0 m=nil [GC sweep wait]:
runtime.gopark(0x1?, 0x0?, 0x0?, 0x0?, 0x0?)
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/proc.go:435 +0xce fp=0xc000085780 sp=0xc000085760 pc=0x1094ef44e
runtime.goparkunlock(...)
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/proc.go:441
runtime.bgsweep(0xc0000b2000)
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/mgcsweep.go:316 +0xdf fp=0xc0000857c8 sp=0xc000085780 pc=0x1094a761f
runtime.gcenable.gowrap1()
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/mgc.go:204 +0x25 fp=0xc0000857e0 sp=0xc0000857c8 pc=0x10949ba65
runtime.goexit({})
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/asm_amd64.s:1700 +0x1 fp=0xc0000857e8 sp=0xc0000857e0 pc=0x1094f76e1
created by runtime.gcenable in goroutine 1
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/mgc.go:204 +0x66

goroutine 4 gp=0xc000003880 m=nil [GC scavenge wait]:
runtime.gopark(0x10000?, 0x10a968be0?, 0x0?, 0x0?, 0x0?)
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/proc.go:435 +0xce fp=0xc000085f78 sp=0xc000085f58 pc=0x1094ef44e
runtime.goparkunlock(...)
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/proc.go:441
runtime.(*scavengerState).park(0x10b53f980)
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/mgcscavenge.go:425 +0x49 fp=0xc000085fa8 sp=0xc000085f78 pc=0x1094a5049
runtime.bgscavenge(0xc0000b2000)
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/mgcscavenge.go:658 +0x59 fp=0xc000085fc8 sp=0xc000085fa8 pc=0x1094a55d9
runtime.gcenable.gowrap2()
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/mgc.go:205 +0x25 fp=0xc000085fe0 sp=0xc000085fc8 pc=0x10949ba05
runtime.goexit({})
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/asm_amd64.s:1700 +0x1 fp=0xc000085fe8 sp=0xc000085fe0 pc=0x1094f76e1
created by runtime.gcenable in goroutine 1
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/mgc.go:205 +0xa5

goroutine 18 gp=0xc000102700 m=nil [finalizer wait]:
runtime.gopark(0x1b8?, 0x1094be5c7?, 0x1?, 0x23?, 0xc000084688?)
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/proc.go:435 +0xce fp=0xc000084630 sp=0xc000084610 pc=0x1094ef44e
runtime.runfinq()
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/mfinal.go:196 +0x107 fp=0xc0000847e0 sp=0xc000084630 pc=0x10949aa27
runtime.goexit({})
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/asm_amd64.s:1700 +0x1 fp=0xc0000847e8 sp=0xc0000847e0 pc=0x1094f76e1
created by runtime.createfing in goroutine 1
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/mfinal.go:166 +0x3d

goroutine 19 gp=0xc000103180 m=nil [chan receive]:
runtime.gopark(0xc00022b720?, 0xc000690018?, 0x60?, 0x7?, 0x1095d0388?)
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/proc.go:435 +0xce fp=0xc000080718 sp=0xc0000806f8 pc=0x1094ef44e
runtime.chanrecv(0xc000112310, 0x0, 0x1)
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/chan.go:664 +0x445 fp=0xc000080790 sp=0xc000080718 pc=0x10948c925
runtime.chanrecv1(0x0?, 0x0?)
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/chan.go:506 +0x12 fp=0xc0000807b8 sp=0xc000080790 pc=0x10948c4b2
runtime.unique_runtime_registerUniqueMapCleanup.func2(...)
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/mgc.go:1796
runtime.unique_runtime_registerUniqueMapCleanup.gowrap1()
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/mgc.go:1799 +0x2f fp=0xc0000807e0 sp=0xc0000807b8 pc=0x10949ebaf
runtime.goexit({})
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/asm_amd64.s:1700 +0x1 fp=0xc0000807e8 sp=0xc0000807e0 pc=0x1094f76e1
created by unique.runtime_registerUniqueMapCleanup in goroutine 1
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/mgc.go:1794 +0x79

goroutine 20 gp=0xc000103500 m=nil [GC worker (idle)]:
runtime.gopark(0x0?, 0x0?, 0x0?, 0x0?, 0x0?)
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/proc.go:435 +0xce fp=0xc000080f38 sp=0xc000080f18 pc=0x1094ef44e
runtime.gcBgMarkWorker(0xc000113730)
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/mgc.go:1423 +0xe9 fp=0xc000080fc8 sp=0xc000080f38 pc=0x10949dec9
runtime.gcBgMarkStartWorkers.gowrap1()
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/mgc.go:1339 +0x25 fp=0xc000080fe0 sp=0xc000080fc8 pc=0x10949dda5
runtime.goexit({})
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/asm_amd64.s:1700 +0x1 fp=0xc000080fe8 sp=0xc000080fe0 pc=0x1094f76e1
created by runtime.gcBgMarkStartWorkers in goroutine 1
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/mgc.go:1339 +0x105

goroutine 34 gp=0xc000504000 m=nil [GC worker (idle)]:
runtime.gopark(0x0?, 0x0?, 0x0?, 0x0?, 0x0?)
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/proc.go:435 +0xce fp=0xc00050a738 sp=0xc00050a718 pc=0x1094ef44e
runtime.gcBgMarkWorker(0xc000113730)
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/mgc.go:1423 +0xe9 fp=0xc00050a7c8 sp=0xc00050a738 pc=0x10949dec9
runtime.gcBgMarkStartWorkers.gowrap1()
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/mgc.go:1339 +0x25 fp=0xc00050a7e0 sp=0xc00050a7c8 pc=0x10949dda5
runtime.goexit({})
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/asm_amd64.s:1700 +0x1 fp=0xc00050a7e8 sp=0xc00050a7e0 pc=0x1094f76e1
created by runtime.gcBgMarkStartWorkers in goroutine 1
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/mgc.go:1339 +0x105

goroutine 5 gp=0xc000003a40 m=nil [GC worker (idle)]:
runtime.gopark(0x0?, 0x0?, 0x0?, 0x0?, 0x0?)
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/proc.go:435 +0xce fp=0xc000086738 sp=0xc000086718 pc=0x1094ef44e
runtime.gcBgMarkWorker(0xc000113730)
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/mgc.go:1423 +0xe9 fp=0xc0000867c8 sp=0xc000086738 pc=0x10949dec9
runtime.gcBgMarkStartWorkers.gowrap1()
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/mgc.go:1339 +0x25 fp=0xc0000867e0 sp=0xc0000867c8 pc=0x10949dda5
runtime.goexit({})
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/asm_amd64.s:1700 +0x1 fp=0xc0000867e8 sp=0xc0000867e0 pc=0x1094f76e1
created by runtime.gcBgMarkStartWorkers in goroutine 1
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/mgc.go:1339 +0x105

goroutine 21 gp=0xc0001036c0 m=nil [GC worker (idle)]:
runtime.gopark(0x0?, 0x0?, 0x0?, 0x0?, 0x0?)
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/proc.go:435 +0xce fp=0xc000081738 sp=0xc000081718 pc=0x1094ef44e
runtime.gcBgMarkWorker(0xc000113730)
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/mgc.go:1423 +0xe9 fp=0xc0000817c8 sp=0xc000081738 pc=0x10949dec9
runtime.gcBgMarkStartWorkers.gowrap1()
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/mgc.go:1339 +0x25 fp=0xc0000817e0 sp=0xc0000817c8 pc=0x10949dda5
runtime.goexit({})
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/asm_amd64.s:1700 +0x1 fp=0xc0000817e8 sp=0xc0000817e0 pc=0x1094f76e1
created by runtime.gcBgMarkStartWorkers in goroutine 1
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/mgc.go:1339 +0x105

goroutine 35 gp=0xc0005041c0 m=nil [GC worker (idle)]:
runtime.gopark(0x0?, 0x0?, 0x0?, 0x0?, 0x0?)
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/proc.go:435 +0xce fp=0xc00050af38 sp=0xc00050af18 pc=0x1094ef44e
runtime.gcBgMarkWorker(0xc000113730)
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/mgc.go:1423 +0xe9 fp=0xc00050afc8 sp=0xc00050af38 pc=0x10949dec9
runtime.gcBgMarkStartWorkers.gowrap1()
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/mgc.go:1339 +0x25 fp=0xc00050afe0 sp=0xc00050afc8 pc=0x10949dda5
runtime.goexit({})
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/asm_amd64.s:1700 +0x1 fp=0xc00050afe8 sp=0xc00050afe0 pc=0x1094f76e1
created by runtime.gcBgMarkStartWorkers in goroutine 1
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/mgc.go:1339 +0x105

goroutine 6 gp=0xc000003c00 m=nil [GC worker (idle)]:
runtime.gopark(0x0?, 0x0?, 0x0?, 0x0?, 0x0?)
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/proc.go:435 +0xce fp=0xc000086f38 sp=0xc000086f18 pc=0x1094ef44e
runtime.gcBgMarkWorker(0xc000113730)
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/mgc.go:1423 +0xe9 fp=0xc000086fc8 sp=0xc000086f38 pc=0x10949dec9
runtime.gcBgMarkStartWorkers.gowrap1()
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/mgc.go:1339 +0x25 fp=0xc000086fe0 sp=0xc000086fc8 pc=0x10949dda5
runtime.goexit({})
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/asm_amd64.s:1700 +0x1 fp=0xc000086fe8 sp=0xc000086fe0 pc=0x1094f76e1
created by runtime.gcBgMarkStartWorkers in goroutine 1
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/mgc.go:1339 +0x105

goroutine 22 gp=0xc000103880 m=nil [GC worker (idle)]:
runtime.gopark(0x0?, 0x0?, 0x0?, 0x0?, 0x0?)
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/proc.go:435 +0xce fp=0xc000081f38 sp=0xc000081f18 pc=0x1094ef44e
runtime.gcBgMarkWorker(0xc000113730)
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/mgc.go:1423 +0xe9 fp=0xc000081fc8 sp=0xc000081f38 pc=0x10949dec9
runtime.gcBgMarkStartWorkers.gowrap1()
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/mgc.go:1339 +0x25 fp=0xc000081fe0 sp=0xc000081fc8 pc=0x10949dda5
runtime.goexit({})
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/asm_amd64.s:1700 +0x1 fp=0xc000081fe8 sp=0xc000081fe0 pc=0x1094f76e1
created by runtime.gcBgMarkStartWorkers in goroutine 1
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/mgc.go:1339 +0x105

goroutine 36 gp=0xc000504380 m=nil [GC worker (idle)]:
runtime.gopark(0x0?, 0x0?, 0x0?, 0x0?, 0x0?)
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/proc.go:435 +0xce fp=0xc00050b738 sp=0xc00050b718 pc=0x1094ef44e
runtime.gcBgMarkWorker(0xc000113730)
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/mgc.go:1423 +0xe9 fp=0xc00050b7c8 sp=0xc00050b738 pc=0x10949dec9
runtime.gcBgMarkStartWorkers.gowrap1()
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/mgc.go:1339 +0x25 fp=0xc00050b7e0 sp=0xc00050b7c8 pc=0x10949dda5
runtime.goexit({})
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/asm_amd64.s:1700 +0x1 fp=0xc00050b7e8 sp=0xc00050b7e0 pc=0x1094f76e1
created by runtime.gcBgMarkStartWorkers in goroutine 1
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/mgc.go:1339 +0x105

goroutine 7 gp=0xc000003dc0 m=nil [GC worker (idle)]:
runtime.gopark(0x0?, 0x0?, 0x0?, 0x0?, 0x0?)
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/proc.go:435 +0xce fp=0xc000087738 sp=0xc000087718 pc=0x1094ef44e
runtime.gcBgMarkWorker(0xc000113730)
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/mgc.go:1423 +0xe9 fp=0xc0000877c8 sp=0xc000087738 pc=0x10949dec9
runtime.gcBgMarkStartWorkers.gowrap1()
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/mgc.go:1339 +0x25 fp=0xc0000877e0 sp=0xc0000877c8 pc=0x10949dda5
runtime.goexit({})
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/asm_amd64.s:1700 +0x1 fp=0xc0000877e8 sp=0xc0000877e0 pc=0x1094f76e1
created by runtime.gcBgMarkStartWorkers in goroutine 1
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/mgc.go:1339 +0x105

goroutine 23 gp=0xc000103a40 m=nil [GC worker (idle)]:
runtime.gopark(0x0?, 0x0?, 0x0?, 0x0?, 0x0?)
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/proc.go:435 +0xce fp=0xc000082738 sp=0xc000082718 pc=0x1094ef44e
runtime.gcBgMarkWorker(0xc000113730)
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/mgc.go:1423 +0xe9 fp=0xc0000827c8 sp=0xc000082738 pc=0x10949dec9
runtime.gcBgMarkStartWorkers.gowrap1()
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/mgc.go:1339 +0x25 fp=0xc0000827e0 sp=0xc0000827c8 pc=0x10949dda5
runtime.goexit({})
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/asm_amd64.s:1700 +0x1 fp=0xc0000827e8 sp=0xc0000827e0 pc=0x1094f76e1
created by runtime.gcBgMarkStartWorkers in goroutine 1
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/mgc.go:1339 +0x105

goroutine 37 gp=0xc000504540 m=nil [GC worker (idle)]:
runtime.gopark(0xc4cfab87f9047?, 0x3?, 0x97?, 0xc3?, 0x0?)
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/proc.go:435 +0xce fp=0xc00050bf38 sp=0xc00050bf18 pc=0x1094ef44e
runtime.gcBgMarkWorker(0xc000113730)
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/mgc.go:1423 +0xe9 fp=0xc00050bfc8 sp=0xc00050bf38 pc=0x10949dec9
runtime.gcBgMarkStartWorkers.gowrap1()
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/mgc.go:1339 +0x25 fp=0xc00050bfe0 sp=0xc00050bfc8 pc=0x10949dda5
runtime.goexit({})
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/asm_amd64.s:1700 +0x1 fp=0xc00050bfe8 sp=0xc00050bfe0 pc=0x1094f76e1
created by runtime.gcBgMarkStartWorkers in goroutine 1
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/mgc.go:1339 +0x105

goroutine 8 gp=0xc0000b6000 m=nil [GC worker (idle)]:
runtime.gopark(0x10b56afc0?, 0x1?, 0x5f?, 0x58?, 0x0?)
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/proc.go:435 +0xce fp=0xc000087f38 sp=0xc000087f18 pc=0x1094ef44e
runtime.gcBgMarkWorker(0xc000113730)
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/mgc.go:1423 +0xe9 fp=0xc000087fc8 sp=0xc000087f38 pc=0x10949dec9
runtime.gcBgMarkStartWorkers.gowrap1()
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/mgc.go:1339 +0x25 fp=0xc000087fe0 sp=0xc000087fc8 pc=0x10949dda5
runtime.goexit({})
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/asm_amd64.s:1700 +0x1 fp=0xc000087fe8 sp=0xc000087fe0 pc=0x1094f76e1
created by runtime.gcBgMarkStartWorkers in goroutine 1
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/mgc.go:1339 +0x105

goroutine 24 gp=0xc000103c00 m=nil [GC worker (idle)]:
runtime.gopark(0xc4cfab87e7e9b?, 0x0?, 0x0?, 0x0?, 0x0?)
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/proc.go:435 +0xce fp=0xc000082f38 sp=0xc000082f18 pc=0x1094ef44e
runtime.gcBgMarkWorker(0xc000113730)
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/mgc.go:1423 +0xe9 fp=0xc000082fc8 sp=0xc000082f38 pc=0x10949dec9
runtime.gcBgMarkStartWorkers.gowrap1()
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/mgc.go:1339 +0x25 fp=0xc000082fe0 sp=0xc000082fc8 pc=0x10949dda5
runtime.goexit({})
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/asm_amd64.s:1700 +0x1 fp=0xc000082fe8 sp=0xc000082fe0 pc=0x1094f76e1
created by runtime.gcBgMarkStartWorkers in goroutine 1
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/mgc.go:1339 +0x105

goroutine 25 gp=0xc000103dc0 m=nil [GC worker (idle)]:
runtime.gopark(0xc4cfab87f55be?, 0x3?, 0xe?, 0x84?, 0x0?)
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/proc.go:435 +0xce fp=0xc000083738 sp=0xc000083718 pc=0x1094ef44e
runtime.gcBgMarkWorker(0xc000113730)
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/mgc.go:1423 +0xe9 fp=0xc0000837c8 sp=0xc000083738 pc=0x10949dec9
runtime.gcBgMarkStartWorkers.gowrap1()
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/mgc.go:1339 +0x25 fp=0xc0000837e0 sp=0xc0000837c8 pc=0x10949dda5
runtime.goexit({})
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/asm_amd64.s:1700 +0x1 fp=0xc0000837e8 sp=0xc0000837e0 pc=0x1094f76e1
created by runtime.gcBgMarkStartWorkers in goroutine 1
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/mgc.go:1339 +0x105

goroutine 38 gp=0xc000504700 m=nil [GC worker (idle)]:
runtime.gopark(0xc4cfab87ecb6a?, 0x3?, 0xa2?, 0x3?, 0x0?)
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/proc.go:435 +0xce fp=0xc00050c738 sp=0xc00050c718 pc=0x1094ef44e
runtime.gcBgMarkWorker(0xc000113730)
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/mgc.go:1423 +0xe9 fp=0xc00050c7c8 sp=0xc00050c738 pc=0x10949dec9
runtime.gcBgMarkStartWorkers.gowrap1()
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/mgc.go:1339 +0x25 fp=0xc00050c7e0 sp=0xc00050c7c8 pc=0x10949dda5
runtime.goexit({})
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/asm_amd64.s:1700 +0x1 fp=0xc00050c7e8 sp=0xc00050c7e0 pc=0x1094f76e1
created by runtime.gcBgMarkStartWorkers in goroutine 1
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/mgc.go:1339 +0x105

goroutine 9 gp=0xc0000b61c0 m=nil [GC worker (idle)]:
runtime.gopark(0xc4cfab87ed2e4?, 0x3?, 0x32?, 0x2?, 0x0?)
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/proc.go:435 +0xce fp=0xc000506738 sp=0xc000506718 pc=0x1094ef44e
runtime.gcBgMarkWorker(0xc000113730)
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/mgc.go:1423 +0xe9 fp=0xc0005067c8 sp=0xc000506738 pc=0x10949dec9
runtime.gcBgMarkStartWorkers.gowrap1()
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/mgc.go:1339 +0x25 fp=0xc0005067e0 sp=0xc0005067c8 pc=0x10949dda5
runtime.goexit({})
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/asm_amd64.s:1700 +0x1 fp=0xc0005067e8 sp=0xc0005067e0 pc=0x1094f76e1
created by runtime.gcBgMarkStartWorkers in goroutine 1
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/mgc.go:1339 +0x105

goroutine 50 gp=0xc0004a41c0 m=nil [sync.WaitGroup.Wait]:
runtime.gopark(0x0?, 0x0?, 0x60?, 0xc0?, 0x0?)
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/proc.go:435 +0xce fp=0xc000508620 sp=0xc000508600 pc=0x1094ef44e
runtime.goparkunlock(...)
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/proc.go:441
runtime.semacquire1(0xc0000b42a0, 0x0, 0x1, 0x0, 0x18)
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/sema.go:188 +0x21d fp=0xc000508688 sp=0xc000508620 pc=0x1094cf67d
sync.runtime_SemacquireWaitGroup(0x0?)
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/sema.go:110 +0x25 fp=0xc0005086c0 sp=0xc000508688 pc=0x1094f0d05
sync.(*WaitGroup).Wait(0x0?)
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/sync/waitgroup.go:118 +0x48 fp=0xc0005086e8 sp=0xc0005086c0 pc=0x109503128
github.com/ollama/ollama/runner/llamarunner.(*Server).run(0xc0000b4280, {0x10ac732c0, 0xc000610140})
	/Users/runner/work/ollama/ollama/runner/llamarunner/runner.go:359 +0x4b fp=0xc0005087b8 sp=0xc0005086e8 pc=0x10995d1eb
github.com/ollama/ollama/runner/llamarunner.Execute.gowrap1()
	/Users/runner/work/ollama/ollama/runner/llamarunner/runner.go:979 +0x28 fp=0xc0005087e0 sp=0xc0005087b8 pc=0x109962668
runtime.goexit({})
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/asm_amd64.s:1700 +0x1 fp=0xc0005087e8 sp=0xc0005087e0 pc=0x1094f76e1
created by github.com/ollama/ollama/runner/llamarunner.Execute in goroutine 1
	/Users/runner/work/ollama/ollama/runner/llamarunner/runner.go:979 +0x4c5

goroutine 51 gp=0xc0004a4380 m=nil [IO wait]:
runtime.gopark(0x5?, 0xc0002d0000?, 0x0?, 0x10?, 0x0?)
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/proc.go:435 +0xce fp=0xc000047948 sp=0xc000047928 pc=0x1094ef44e
runtime.netpollblock(0x109511145?, 0x948a186?, 0x1?)
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/netpoll.go:575 +0xf7 fp=0xc000047980 sp=0xc000047948 pc=0x1094b5477
internal/poll.runtime_pollWait(0x152521618, 0x72)
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/netpoll.go:351 +0x85 fp=0xc0000479a0 sp=0xc000047980 pc=0x1094ee6a5
internal/poll.(*pollDesc).wait(0xc0001d0b80?, 0xc0002d0000?, 0x0)
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/internal/poll/fd_poll_runtime.go:84 +0x27 fp=0xc0000479c8 sp=0xc0000479a0 pc=0x1095747c7
internal/poll.(*pollDesc).waitRead(...)
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/internal/poll/fd_poll_runtime.go:89
internal/poll.(*FD).Read(0xc0001d0b80, {0xc0002d0000, 0x1000, 0x1000})
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/internal/poll/fd_unix.go:165 +0x27a fp=0xc000047a60 sp=0xc0000479c8 pc=0x109575aba
net.(*netFD).Read(0xc0001d0b80, {0xc0002d0000?, 0xc000047ad0?, 0x109574c85?})
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/net/fd_posix.go:55 +0x25 fp=0xc000047aa8 sp=0xc000047a60 pc=0x1095eb9e5
net.(*conn).Read(0xc00051a068, {0xc0002d0000?, 0x0?, 0x0?})
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/net/net.go:194 +0x45 fp=0xc000047af0 sp=0xc000047aa8 pc=0x1095f9485
net/http.(*connReader).Read(0xc000172480, {0xc0002d0000, 0x1000, 0x1000})
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/net/http/server.go:798 +0x159 fp=0xc000047b40 sp=0xc000047af0 pc=0x1097e7299
bufio.(*Reader).fill(0xc000598240)
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/bufio/bufio.go:113 +0x103 fp=0xc000047b78 sp=0xc000047b40 pc=0x109610643
bufio.(*Reader).Peek(0xc000598240, 0x4)
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/bufio/bufio.go:152 +0x53 fp=0xc000047b98 sp=0xc000047b78 pc=0x109610773
net/http.(*conn).serve(0xc000246090, {0x10ac73288, 0xc000172390})
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/net/http/server.go:2137 +0x785 fp=0xc000047fb8 sp=0xc000047b98 pc=0x1097ed085
net/http.(*Server).Serve.gowrap3()
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/net/http/server.go:3454 +0x28 fp=0xc000047fe0 sp=0xc000047fb8 pc=0x1097f27e8
runtime.goexit({})
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/runtime/asm_amd64.s:1700 +0x1 fp=0xc000047fe8 sp=0xc000047fe0 pc=0x1094f76e1
created by net/http.(*Server).Serve in goroutine 1
	/Users/runner/hostedtoolcache/go/1.24.1/arm64/src/net/http/server.go:3454 +0x485

rax    0x0
rbx    0x6
rcx    0x700009d53348
rdx    0x0
rdi    0x1c03
rsi    0x6
rbp    0x700009d53370
rsp    0x700009d53348
r8     0xd4b00000000
r9     0x130300000003
r10    0x7ff8445ed9c0
r11    0x246
r12    0xc000090ad8
r13    0x6c
r14    0x1c03
r15    0x16
rip    0x7ff8029a9846
rflags 0x246
cs     0x7
fs     0x0
gs     0x0
time=2026-01-15T22:53:36.115+04:00 level=ERROR source=server.go:265 msg="llama runner terminated" error="exit status 2"
time=2026-01-15T22:53:36.239+04:00 level=INFO source=sched.go:470 msg="Load failed" model=/Users/[USER]/.ollama/models/blobs/sha256-804814d6c2a3ac31e543308830cce709fdc0dddb70bb464324b39cceed58c08a error="llama runner process has terminated: error:attach failed: attach failed (Not allowed to attach to process.  Look in the console messages (Console.app), near the debugserver entries, when the attach failed.  The subsystem that denied the attach permission will likely have logged an informative message about why it was denied.)"
[GIN] 2026/01/15 - 22:53:36 | 500 |  599.035634ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2026/01/15 - 22:53:47 | 200 |    3.365318ms |       127.0.0.1 | GET      "/api/tags"
